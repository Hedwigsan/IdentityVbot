import easyocr
import cv2
import numpy as np
from typing import Dict, List, Tuple, Optional
import re
from pathlib import Path

class OCRProcessor:
    def __init__(self):
        self.reader = easyocr.Reader(['ja', 'en'], gpu=False)
        
        # ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒï¼ˆå¿…é ˆï¼‰
        self.icon_templates = {}
        self._load_icon_templates()
        
        # ãƒãƒƒãƒ—åãƒªã‚¹ãƒˆ
        self.map_names = [
            "è–å¿ƒç—…é™¢", "è»éœ€å·¥å ´", "èµ¤ã®æ•™ä¼š", "æ¹–æ™¯æ‘",
            "æœˆã®æ²³å…¬åœ’", "ä¸­è¯è¡—", "ç™½ç ‚è¡—", "æ°¸çœ é®"
        ]
        
        # ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®è¨­å®šï¼ˆç›¸å¯¾åº§æ¨™ï¼‰
        self.layout = {
            "icon_x_ratio": (0.03, 0.12),   # ã‚¢ã‚¤ã‚³ãƒ³ã®Xåº§æ¨™ç¯„å›²ï¼ˆç”»é¢å¹…ã®3%~12%ï¼‰
            "icon_size_ratio": 0.06,         # ã‚¢ã‚¤ã‚³ãƒ³ã‚µã‚¤ã‚ºï¼ˆç”»é¢å¹…ã®6%ï¼‰
            "survivor_y_start": 0.25,        # ã‚µãƒã‚¤ãƒãƒ¼ã‚¨ãƒªã‚¢é–‹å§‹ï¼ˆç”»é¢ã®25%ï¼‰
            "survivor_y_end": 0.85,          # ã‚µãƒã‚¤ãƒãƒ¼ã‚¨ãƒªã‚¢çµ‚äº†ï¼ˆç”»é¢ã®85%ï¼‰
            "use_auto_detect": True,         # è‡ªå‹•æ¤œå‡ºã‚’æœ‰åŠ¹åŒ–
        }
    
    def _load_icon_templates(self):
        """ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒã‚’èª­ã¿è¾¼ã¿ï¼ˆå¿…é ˆï¼‰"""
        template_dir = Path("templates/icons")
        
        if not template_dir.exists():
            print("âš ï¸  templates/icons/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ç”»åƒã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚è©³ç´°: ICON_GUIDE.md")
            return
        
        for icon_file in template_dir.glob("*.png"):
            char_name = icon_file.stem
            template = cv2.imread(str(icon_file), cv2.IMREAD_COLOR)
            if template is not None:
                # è¤‡æ•°ã‚µã‚¤ã‚ºã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§ï¼‰
                self.icon_templates[char_name] = {
                    'original': template,
                    'sizes': [
                        cv2.resize(template, (60, 60)),
                        cv2.resize(template, (70, 70)),
                        cv2.resize(template, (80, 80)),
                        cv2.resize(template, (90, 90)),
                    ]
                }
        
        if self.icon_templates:
            print(f"âœ… {len(self.icon_templates)}å€‹ã®ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        else:
            print("âš ï¸  ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ICON_GUIDE.mdã‚’å‚ç…§ã—ã¦ãã ã•ã„")
    
    def process_image(self, image_bytes: bytes) -> Dict:
        """ç”»åƒã‹ã‚‰è©¦åˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if img is None:
            raise Exception("ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # OCRå®Ÿè¡Œ
        results = self.reader.readtext(img)
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
        match_data = self._parse_match_data(results, img)
        
        return match_data
    
    def _parse_match_data(self, results: List, img: np.ndarray) -> Dict:
        """OCRçµæœã‹ã‚‰è©¦åˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        height, width = img.shape[:2]
        
        match_data = {
            "result": None,
            "map_name": None,
            "duration": None,
            "survivors": []
        }
        
        # Yåº§æ¨™ã§ã‚½ãƒ¼ãƒˆï¼ˆä¸Šã‹ã‚‰é †ã«å‡¦ç†ï¼‰
        sorted_results = sorted(results, key=lambda x: (x[0][0][1] + x[0][2][1]) / 2)
        
        for bbox, text, conf in sorted_results:
            # åº§æ¨™ã‚’æ­£è¦åŒ–
            y_center = (bbox[0][1] + bbox[2][1]) / 2 / height
            x_center = (bbox[0][0] + bbox[2][0]) / 2 / width
            
            # å‹åˆ©/æ•—åŒ—ã‚’æ¤œå‡º
            if "å‹åˆ©" in text:
                match_data["result"] = "å‹åˆ©"
            elif "æ•—åŒ—" in text:
                match_data["result"] = "æ•—åŒ—"
            
            # ãƒãƒƒãƒ—åã‚’æ¤œå‡º
            for map_name in self.map_names:
                if map_name in text:
                    match_data["map_name"] = map_name
                    break
            
            # ä½¿ç”¨æ™‚é–“ã‚’æ¤œå‡ºï¼ˆä¾‹: "4:17"ï¼‰
            time_match = re.search(r'\d+:\d+', text)
            if time_match:
                match_data["duration"] = time_match.group()
        
        # ã‚µãƒã‚¤ãƒãƒ¼æƒ…å ±ã‚’æŠ½å‡ºï¼ˆç”»åƒèªè­˜ãƒ™ãƒ¼ã‚¹ï¼‰
        match_data["survivors"] = self._extract_survivors(sorted_results, img)
        
        return match_data
    
    def _extract_survivors(self, results: List, img: np.ndarray) -> List[Dict]:
        """ã‚µãƒã‚¤ãƒãƒ¼4äººã®æƒ…å ±ã‚’æŠ½å‡ºï¼ˆç”»åƒèªè­˜ãƒ™ãƒ¼ã‚¹ï¼‰"""
        height, width = img.shape[:2]
        survivors = []
        
        # 1. ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã®ä½ç½®ã‚’æ¤œå‡ºï¼ˆç”»é¢ã‚µã‚¤ã‚ºå¯¾å¿œï¼‰
        icon_positions = self._detect_icon_positions(img)
        
        print(f"\nğŸ” ã‚µãƒã‚¤ãƒãƒ¼èªè­˜é–‹å§‹... (ç”»é¢ã‚µã‚¤ã‚º: {width}x{height})")
        
        # 2. å„ä½ç½®ã§ã‚¢ã‚¤ã‚³ãƒ³ã‚’èªè­˜
        for position, icon_data in enumerate(icon_positions, 1):
            print(f"\nã‚µãƒã‚¤ãƒãƒ¼ {position}:")
            
            # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’å±•é–‹
            if len(icon_data) == 4:
                icon_x, icon_y, icon_w, icon_h = icon_data
            else:
                # å¤ã„å½¢å¼ï¼ˆäº’æ›æ€§ï¼‰
                icon_x, icon_y = icon_data
                icon_w = icon_h = int(width * self.layout['icon_size_ratio'])
            
            survivor = {
                "position": position,
                "character": None,
                "kite_time": None,
                "decode_progress": None,
                "board_hits": 0,
                "rescues": 0,
                "heals": 0
            }
            
            # ã‚¢ã‚¤ã‚³ãƒ³ã‚’ç”»åƒèªè­˜
            char_name = self._match_character_icon(
                img, 
                icon_x, 
                icon_y,
                width=icon_w,
                height=icon_h
            )
            
            if char_name:
                survivor["character"] = char_name
            else:
                print(f"  âŒ ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ (ä½ç½®: x={icon_x}, y={icon_y})")
            
            # ãã®è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            row_data = self._get_row_text_data(results, icon_y + icon_h // 2, height)
            
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            survivor.update(row_data)
            
            if survivor["character"]:  # ã‚­ãƒ£ãƒ©ãŒèªè­˜ã§ããŸå ´åˆã®ã¿è¿½åŠ 
                survivors.append(survivor)
        
        print(f"\nâœ… {len(survivors)}äººã®ã‚µãƒã‚¤ãƒãƒ¼ã‚’èªè­˜ã—ã¾ã—ãŸ\n")
        
        return survivors
    
    def _get_row_text_data(self, results: List, target_y: int, img_height: int) -> Dict:
        """
        æŒ‡å®šYåº§æ¨™ä»˜è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ•°å€¤æƒ…å ±ã‚’æŠ½å‡º
        
        Args:
            results: OCRçµæœ
            target_y: å¯¾è±¡è¡Œã®Yåº§æ¨™
            img_height: ç”»åƒã®é«˜ã•
        
        Returns:
            ç‰½åˆ¶æ™‚é–“ã€è§£èª­é€²æ—ãªã©ã®ãƒ‡ãƒ¼ã‚¿
        """
        data = {
            "kite_time": None,
            "decode_progress": None,
            "board_hits": 0,
            "rescues": 0,
            "heals": 0
        }
        
        # target_yä»˜è¿‘ï¼ˆÂ±50pxï¼‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†
        row_texts = []
        for bbox, text, conf in results:
            y_center = (bbox[0][1] + bbox[2][1]) / 2
            
            if abs(y_center - target_y) < 50:
                row_texts.append((bbox, text, conf))
        
        # Xåº§æ¨™ã§ã‚½ãƒ¼ãƒˆï¼ˆå·¦ã‹ã‚‰å³ã¸ï¼‰
        row_texts.sort(key=lambda x: x[0][0][0])
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        for bbox, text, conf in row_texts:
            # ç‰½åˆ¶æ™‚é–“ï¼ˆä¾‹: "20s", "34s"ï¼‰
            time_match = re.search(r'(\d+)s', text)
            if time_match:
                data["kite_time"] = time_match.group()
                print(f"  â±ï¸  ç‰½åˆ¶æ™‚é–“: {data['kite_time']}")
            
            # è§£èª­é€²æ—ï¼ˆä¾‹: "112%", "0%"ï¼‰
            progress_match = re.search(r'(\d+)%', text)
            if progress_match:
                data["decode_progress"] = progress_match.group()
                print(f"  ğŸ“Š è§£èª­é€²æ—: {data['decode_progress']}")
            
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¿/æ•‘åŠ©/æ²»ç™‚ï¼‰
            if text.isdigit() and len(text) <= 2:
                num = int(text)
                if data["board_hits"] == 0:
                    data["board_hits"] = num
                elif data["rescues"] == 0:
                    data["rescues"] = num
                elif data["heals"] == 0:
                    data["heals"] = num
        
        return data
    
    def _match_character_icon(self, img: np.ndarray, x: int, y: int, width: int = 100, height: int = 100) -> Optional[str]:
        """
        æŒ‡å®šåº§æ¨™å‘¨è¾ºã®ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã‚’ç”»åƒãƒãƒƒãƒãƒ³ã‚°ã§è­˜åˆ¥
        
        Args:
            img: å…ƒç”»åƒ
            x, y: ã‚¢ã‚¤ã‚³ãƒ³ã®å·¦ä¸Šåº§æ¨™
            width, height: ã‚¢ã‚¤ã‚³ãƒ³é ˜åŸŸã®ã‚µã‚¤ã‚º
        
        Returns:
            ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
        """
        if not self.icon_templates:
            print("âš ï¸  ã‚¢ã‚¤ã‚³ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        # ã‚¢ã‚¤ã‚³ãƒ³é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã—
        y1 = max(0, y)
        y2 = min(img.shape[0], y + height)
        x1 = max(0, x)
        x2 = min(img.shape[1], x + width)
        
        icon_region = img[y1:y2, x1:x2]
        
        if icon_region.size == 0:
            return None
        
        # å„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        best_match = None
        best_score = 0.65  # é–¾å€¤ï¼ˆ65%ä»¥ä¸Šã®ä¸€è‡´ã§èªè­˜ï¼‰
        
        for char_name, template_data in self.icon_templates.items():
            # è¤‡æ•°ã‚µã‚¤ã‚ºã§è©¦ã™
            for template in template_data['sizes']:
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒã‚¢ã‚¤ã‚³ãƒ³é ˜åŸŸã‚ˆã‚Šå¤§ãã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if template.shape[0] > icon_region.shape[0] or template.shape[1] > icon_region.shape[1]:
                    continue
                
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒƒãƒãƒ³ã‚°
                try:
                    result = cv2.matchTemplate(icon_region, template, cv2.TM_CCOEFF_NORMED)
                    _, max_val, _, _ = cv2.minMaxLoc(result)
                    
                    if max_val > best_score:
                        best_score = max_val
                        best_match = char_name
                except cv2.error:
                    continue
        
        if best_match:
            print(f"  ğŸ¯ ã‚¢ã‚¤ã‚³ãƒ³èªè­˜: {best_match} (ä¿¡é ¼åº¦: {best_score:.2%})")
        
        return best_match
    
    def _detect_icon_positions(self, img: np.ndarray) -> List[Tuple[int, int]]:
        """
        ç”»åƒå†…ã®ã‚­ãƒ£ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã®ä½ç½®ã‚’æ¤œå‡ºï¼ˆç”»é¢ã‚µã‚¤ã‚ºå¯¾å¿œï¼‰
        
        Returns:
            [(x, y, width, height), ...] ã®ãƒªã‚¹ãƒˆ
        """
        height, width = img.shape[:2]
        
        # ç›¸å¯¾åº§æ¨™ã‹ã‚‰å®Ÿåº§æ¨™ã«å¤‰æ›
        icon_size = int(width * self.layout['icon_size_ratio'])
        x_start = int(width * self.layout['icon_x_ratio'][0])
        x_end = int(width * self.layout['icon_x_ratio'][1])
        
        y_start = int(height * self.layout['survivor_y_start'])
        y_end = int(height * self.layout['survivor_y_end'])
        
        # è‡ªå‹•æ¤œå‡ºã‚’è©¦ã¿ã‚‹
        if self.layout.get('use_auto_detect', False):
            detected = self._auto_detect_icons(img, x_start, x_end, y_start, y_end)
            if detected and len(detected) >= 2:  # 2äººä»¥ä¸Šæ¤œå‡ºã§ããŸã‚‰æ¡ç”¨
                print(f"âœ… è‡ªå‹•æ¤œå‡º: {len(detected)}å€‹ã®ã‚¢ã‚¤ã‚³ãƒ³ä½ç½®ã‚’æ¤œå‡º")
                return detected
            else:
                print("âš ï¸  è‡ªå‹•æ¤œå‡ºå¤±æ•—ã€æ¨å®šä½ç½®ã‚’ä½¿ç”¨")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç­‰é–“éš”ã§æ¨å®š
        positions = []
        row_height = (y_end - y_start) / 4
        
        for i in range(4):
            y = int(y_start + i * row_height)
            x = x_start
            positions.append((x, y, icon_size, icon_size))
        
        return positions
    
    def _auto_detect_icons(self, img: np.ndarray, x_min: int, x_max: int, 
                          y_min: int, y_max: int) -> List[Tuple[int, int, int, int]]:
        """
        è¼ªéƒ­æ¤œå‡ºã§ã‚¢ã‚¤ã‚³ãƒ³ä½ç½®ã‚’è‡ªå‹•æ¤œå‡º
        
        Returns:
            [(x, y, width, height), ...] ã®ãƒªã‚¹ãƒˆ
        """
        # æ¤œå‡ºã‚¨ãƒªã‚¢ã‚’åˆ‡ã‚Šå‡ºã—
        roi = img[y_min:y_max, x_min:x_max]
        
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        
        # ã‚¨ãƒƒã‚¸æ¤œå‡º
        edges = cv2.Canny(gray, 50, 150)
        
        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # ã‚¢ã‚¤ã‚³ãƒ³ã‚‰ã—ã„çŸ©å½¢ã‚’æŠ½å‡º
        icon_candidates = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶
            area = w * h
            aspect_ratio = w / h if h > 0 else 0
            
            # ã‚¢ã‚¤ã‚³ãƒ³ã®æ¡ä»¶:
            # - é¢ç©ãŒé©åˆ‡ï¼ˆç”»åƒã®0.3%~3%ï¼‰
            # - ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãŒæ­£æ–¹å½¢ã«è¿‘ã„ï¼ˆ0.8~1.2ï¼‰
            # - Xåº§æ¨™ãŒå·¦å´
            img_area = roi.shape[0] * roi.shape[1]
            
            if (0.003 < area / img_area < 0.03 and
                0.8 < aspect_ratio < 1.2 and
                x < roi.shape[1] * 0.3):  # å·¦å´30%ä»¥å†…
                
                # å…ƒç”»åƒã§ã®åº§æ¨™ã«å¤‰æ›
                abs_x = x_min + x
                abs_y = y_min + y
                icon_candidates.append((abs_x, abs_y, w, h))
        
        # Yåº§æ¨™ã§ã‚½ãƒ¼ãƒˆï¼ˆä¸Šã‹ã‚‰é †ï¼‰
        icon_candidates.sort(key=lambda c: c[1])
        
        # æœ€å¤§4å€‹ã¾ã§
        return icon_candidates[:4]

